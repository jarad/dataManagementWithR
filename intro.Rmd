# Introduction {#intro}

Data management comprises the following steps

1. data collection,
1. data cleaning,
1. data validation,
1. data visualization, and
1. data analysis

Thus, in this text, we will discuss each of these steps in turn and
I will provide my opinion on how to perform these steps.
Generally, the advice is agnostic about the software being used, 
but in places the advice will be specific to the 
[R software environment](http://r-project.org/).

The most important part of data management is 

    Have a plan and stick to it!
    
If you have a plan and stick to it, 
then it will be relatively easy to make a change to the plan.
In constrast, 
if you don't have a plan or don't stick to it, then all bets are off.

So don't try to perfect your data management at first. 
Instead, 

1. set a plan, 
1. periodically review the plan, and 
1. revise the plan as needed.

## Principles

Data management is one piece of the pipeline in scientific discovery and 
development. 
The purpose of data management is to make data analysis and 
therefore science itself accurate, easy, and reproducible.

I have some principles that aim to help the design of a data management plan

- Be consistent
- Have ownership
- Store each piece of data only once
- Don't touch the raw data
- Leave as much of the work as possible to the computer


### Be consistent

If you are consistent, 
then any changes you want to make in the future can easily be accomplished in 
a script. 
But if you are inconsistent, 
then it will make writing a script difficult and you may be in the situation
where you will need to make manual changes. 

### Have ownership

Individuals who are responsible for entering the data should feel ownership
over their data.
This means that the individual is responsible for entering the data, 
making sure it is correct, 
and fixing errors as errors are found.


### Store each piece of data only once

    To err is human.
    
We will make mistakes and that is to be expected.
When a mistake is discovered it will need to be fixed.
If each piece of data is stored only once, 
then there is only one place to fix the mistake. 
If each piece of data is stored in multiple locations,
then it will need to be fixed in each of those locations.
Unfortunately, it is typically hard to know how many locations a piece of data
comes from. 
Therefore, most likely, 
what will occur is that you will fix the mistake in some places, 
but not all and then your resulting analysis will have errors.


### Don't touch the raw data

We will discuss exactly what raw data is later, 
but for now, the raw data is the data as it was recorded.
Don't touch the raw data means that you should record the data once and then
never write to it again. 
You can feel free to read the raw data as much as you want, just 
never write to it again. 
Any change that you do make to the raw data should be recorded.



### Leave as much of the work as possible to the computer

The raw data will be combined using scripts and 
data analyses will be performed using scripts.
When an error is found in the raw data, 
it will be easy to re-run the scripts.
When an error is found in the scripts, 
the error will be fixed and the script will be re-run.



